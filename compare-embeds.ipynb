{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading word embeddings\n",
    "\n",
    "1. Run the first cell. When the upload button appears, upload `ngrams.txt`, `both_64.txt`, `lstm_64.txt`, and `img_aug_64.txt`\n",
    "2. Run the remaining cells in order. After about a minute of computing distances, interactive controls will appear at the bottom of the page.\n",
    "\n",
    "The sliders control which pairs of signs are displayed. You can adjust the minimum and maximum similarity allowed for each model, as well as filter out rare signs. The default settings show signs with high LM similarity and relatively low image similarity (signs that seem to function similarly but don't look like variants.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, widgets\n",
    "\n",
    "upload = widgets.FileUpload(\n",
    "    accept='',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=True  # True to accept multiple files upload else False\n",
    ")\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vec(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "#     with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "    with io.BytesIO(upload.value[emb_path][\"content\"]) as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.decode('utf-8')\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, 'word found twice : %s'%(word,)\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id\n",
    "\n",
    "both_path = 'both_64.txt' # LM with image inputs\n",
    "img_path = 'img_aug_64.txt' # Image classification\n",
    "# img_path = './embeddings/img_pre_64.txt' # Image classification\n",
    "lm_path = 'lstm_64.txt' # LM with sign names\n",
    "\n",
    "nmax = 50000  # maximum number of word embeddings to load\n",
    "\n",
    "both_embeddings, both_id2word, both_word2id = load_vec(both_path, nmax)\n",
    "img_embeddings, img_id2word, img_word2id = load_vec(img_path, nmax)\n",
    "lm_embeddings, lm_id2word, lm_word2id = load_vec(lm_path, nmax)\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "ngrams = defaultdict(int)\n",
    "with io.BytesIO(upload.value['ngrams.txt']['content']) as fp:\n",
    "    ngrams.update( json.load(fp) )\n",
    "    \n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cosine(word_emb, word2_emb):\n",
    "    similarity = (word2_emb / np.linalg.norm(word2_emb)).dot(word_emb / np.linalg.norm(word_emb))\n",
    "    return similarity\n",
    "\n",
    "def get_similarity(word, word2, embeddings, word2id):\n",
    "    word_emb = embeddings[word2id[word]]\n",
    "    word2_emb = embeddings[word2id[word2]]\n",
    "    similarity = cosine(word_emb, word2_emb)\n",
    "    return similarity\n",
    "\n",
    "pairs = []\n",
    "all_words = sorted(list(set(\n",
    "    word for word in both_word2id \n",
    "    if word in img_word2id \n",
    "    and word in lm_word2id\n",
    ")))\n",
    "\n",
    "for i, word1 in enumerate(all_words):\n",
    "    print('Computing distances %.02f%%'%(100*i/len(all_words)),end='\\r')\n",
    "    for j, word2 in enumerate(all_words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "\n",
    "        both_similarity = get_similarity(word1, word2, both_embeddings, both_word2id)\n",
    "        img_similarity = get_similarity(word1, word2, img_embeddings, img_word2id)\n",
    "        lm_similarity = get_similarity(word1, word2, lm_embeddings, lm_word2id)\n",
    "        \n",
    "        pairs.append( (both_similarity, lm_similarity, img_similarity, word1, word2) )\n",
    "print('Finished computing distances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compare_signs(\n",
    "    min_sim_lm, max_sim_lm, \n",
    "    min_sim_img, max_sim_img, \n",
    "    min_sim_both, max_sim_both, \n",
    "    #output_size, \n",
    "    min_freq, \n",
    "    sort_key):\n",
    "\n",
    "    output_size = 500 # Limit this so updates aren't terribly slow when user adjusts sliders\n",
    "    \n",
    "    print(\"{0}\\t{1}\\t\\t{2}\".format(\" COMBINED\", \"    LM\", \"  IMAGE\"))\n",
    "\n",
    "    # Filter pairs that match the slider values:\n",
    "    result = []\n",
    "    for both_sim, lm_sim, img_sim, word1, word2 in pairs:\n",
    "        count1 = ngrams[word1.replace(\"-\",\"~\")]\n",
    "        count2 = ngrams[word2.replace(\"-\",\"~\")]\n",
    "        if count1 < min_freq or count2 < min_freq:\n",
    "            continue\n",
    "        if (img_sim >= min_sim_img and img_sim <= max_sim_img) \\\n",
    "        and (lm_sim >= min_sim_lm and lm_sim <= max_sim_lm) \\\n",
    "        and (both_sim >= min_sim_both and both_sim <= max_sim_both):\n",
    "            result.append( (both_sim, lm_sim, img_sim, word1, word2) )\n",
    "            \n",
    "    # Sort and display in order:\n",
    "    for i, (both_sim, lm_sim, img_sim, word1, word2) \\\n",
    "    in enumerate(sorted(result,key=lambda x:x[sort_key],reverse=True)):\n",
    "        count1 = ngrams[word1.replace(\"-\",\"~\")]\n",
    "        count2 = ngrams[word2.replace(\"-\",\"~\")]\n",
    "        if count1 < min_freq or count2 < min_freq:\n",
    "            continue\n",
    "        print(\"{0:+f}\\t{1:+f}\\t{2:+f}\\t{3} ({5}) \\t{4} ({6})\".format(both_sim, lm_sim, img_sim, word1, word2, \n",
    "                                                                    count1, count2\n",
    "                                                                   ))\n",
    "        if i > output_size:\n",
    "            break\n",
    "            \n",
    "interact(\n",
    "    compare_signs,\n",
    "    min_sim_lm=FloatSlider(min=-1, max=1, step=0.01, value=0.8, continuous_update=False),\n",
    "    max_sim_lm=FloatSlider(min=-1, max=1, step=0.01, value=1, continuous_update=False),\n",
    "    min_sim_img=FloatSlider(min=-1, max=1, step=0.01, value=-1, continuous_update=False),\n",
    "    max_sim_img=FloatSlider(min=-1, max=1, step=0.01, value=0.4, continuous_update=False),\n",
    "    min_sim_both=FloatSlider(min=-1, max=1, step=0.01, value=-1, continuous_update=False),\n",
    "    max_sim_both=FloatSlider(min=-1, max=1, step=0.01, value=1, continuous_update=False),\n",
    "    #output_size=IntSlider(min=0, max=10000, step=200, value=300, continuous_update=False),\n",
    "    min_freq=IntSlider(min=0, max=1000, step=1, value=5, continuous_update=False),\n",
    "    sort_key=[('both',0), ('lm',1), ('img',2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
